# Ollama URL for the backend to connect
# The path '/ollama' will be redirected to the specified backend URL
OLLAMA_BASE_URL='http://localhost:11434'

# OpenAI-compatible API configuration
# Can be used with OpenAI or compatible providers (e.g., LMStudio, GroqCloud, Mistral, OpenRouter, AI Badgr)
OPENAI_API_BASE_URL=''
OPENAI_API_KEY=''

# AI Badgr (Budget/Utility OpenAI-compatible provider)
# Uncomment to use AI Badgr
# OPENAI_API_BASE_URL='https://aibadgr.com/api/v1'
# OPENAI_API_KEY='your_aibadgr_api_key'

# AUTOMATIC1111_BASE_URL="http://localhost:7860"

# For production, you should only need one host as
# fastapi serves the svelte-kit built frontend and backend from the same host and port.
# To test with CORS locally, you can set something like
# CORS_ALLOW_ORIGIN='http://localhost:5173;http://localhost:8080'
CORS_ALLOW_ORIGIN='*'

# For production you should set this to match the proxy configuration (127.0.0.1)
FORWARDED_ALLOW_IPS='*'

# DO NOT TRACK
SCARF_NO_ANALYTICS=true
DO_NOT_TRACK=true
ANONYMIZED_TELEMETRY=false